{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde883fd-1389-47af-a85d-c9eb670dcd9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/risto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, EarlyStoppingCallback, MBartConfig\n",
    "from transformers import MBartForConditionalGeneration, MBartTokenizerFast,MBartTokenizer,Trainer, TrainingArguments\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from hftrim.TokenizerTrimmer import TokenizerTrimmer\n",
    "from hftrim.ModelTrimmers import MBartTrimmer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import Dataset\n",
    "from random import randrange\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from lsg_converter import LSGConverter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ea95d5-17ce-4915-b20a-c2119e3c6892",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902452d9-f3c2-4085-8fa6-5c7eaf94ea14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3ccec9-1a90-4e52-93df-277c06e0dedd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e69b14-4a03-463e-b71b-79c6b800edc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf42950-9405-4d2a-bb56-46991f67c626",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c325f1-27e3-46af-9918-72289c66fad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9758d323-6b9d-4bdf-9ae1-19aaebb450a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6685f2-29ac-4018-9486-b33f823f014a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef187b1-9e0e-44ea-bf56-2c1b114dc6cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id=\"facebook/mbart-large-cc25\"\n",
    "src_lang = \"et_EE\" # Example source language code\n",
    "tgt_lang = \"et_EE\" # Example target language code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0df83dd6-353c-4e01-874b-1fb76d377560",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = MBartTokenizerFast.from_pretrained(model_id)\n",
    "tokenizer_slow = MBartTokenizer.from_pretrained(model_id)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0fe507c-b7b8-48ca-b7c5-3a5fbf57ab38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Important: Set both source and target languages\n",
    "tokenizer.src_lang = src_lang\n",
    "tokenizer.tgt_lang = tgt_lang\n",
    "\n",
    "tokenizer_slow.src_lang = src_lang\n",
    "tokenizer_slow.tgt_lang = tgt_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0e0b57c-46de-424e-81a8-e67640e0d45e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41913215486098887\n",
      "0.41913215486098887\n"
     ]
    }
   ],
   "source": [
    "def msize(m):\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "#share of params in embedding\n",
    "print(msize(model.model.shared) / msize(model))   \n",
    "print(msize(model.lm_head) / msize(model))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2ca13-1507-402d-bb77-289d594c6219",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0488a3e2-a550-4014-9f58-25686dd78a8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 3516\n",
      "Test dataset size: 308\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"riigikogu\"\n",
    "df=pd.read_excel('data/riigikogu/for_summarization_mbart_2048_chunks_summaries.xlsx')\n",
    "df_train=df[df.split=='train']\n",
    "df_test=df[df.split=='test']\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ed5008b-5135-4442-9de1-565471151878",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b36aebde0a4a73b3f479733a91578f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac383754ac744feb8ee19deb0209d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset=train_dataset.filter(lambda example, idx: example['summary'] is not None and example['text'] is not None, with_indices=True)\n",
    "test_dataset = test_dataset.filter(lambda example, idx: example['summary'] is not None and example['text'] is not None, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "607554e0-274a-417b-a5d9-12f19d42e9af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 3516\n",
      "Test dataset size: 308\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10c473-40b5-4f9a-825d-ecb94eeef887",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## trim models vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33d3e93b-68bc-4acf-b5c9-aa9978e2e734",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7032"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts4vocab=train_dataset['text']+train_dataset['summary']\n",
    "len(texts4vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f78824c-4d9e-4121-bcfa-0f08e6d3beec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = MBartConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13803b0c-fbe6-49c5-bd71-914a36224c0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 250000/250000 [00:00<00:00, 1141163.13it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): Embedding(16273, 1024, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): Embedding(16273, 1024, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): Embedding(16273, 1024, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=16273, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim tokenizer\n",
    "tokenizer_slow_trim = TokenizerTrimmer(tokenizer_slow)\n",
    "tokenizer_slow_trim.make_vocab(texts4vocab)\n",
    "tokenizer_slow_trim.make_tokenizer()\n",
    "\n",
    "# trim model\n",
    "model_trim = MBartTrimmer(model, config, tokenizer_slow_trim.trimmed_tokenizer)\n",
    "model_trim.make_weights(tokenizer_slow_trim.trimmed_vocab_ids)\n",
    "model_trim.make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715da82-494a-4ee3-b30f-14da9183aab0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save trimmed model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11147006-b556-4bd6-8317-a7d41556213c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_slow_trim.trimmed_tokenizer.save_pretrained('mbart-large-cc25_et_rk')\n",
    "model_trim.trimmed_model.save_pretrained('mbart-large-cc25_et_rk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9eca1-6156-4581-a51e-0271b102f266",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e858cc4a-d4cc-4506-90be-8e7b825c0383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MBartTokenizerFast.from_pretrained(\"mbart-large-cc25_et_rk/\", from_slow=True)\n",
    "tokenizer.src_lang = src_lang\n",
    "tokenizer.tgt_lang = tgt_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c67d1da-805a-4a30-a6da-cbee306fb1c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained('mbart-large-cc25_et_rk', max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b421bdd-e71f-4f62-b83a-a0bc1a7ac1c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load model and make it accepting longer sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20490531-b219-4b41-92cb-6553ea6e0fe1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/risto/.local/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:1067: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/risto/.local/lib/python3.9/site-packages/transformers/configuration_utils.py:508: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "/home/risto/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:2759: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Some weights of LSGMBartForConditionalGeneration were not initialized from the model checkpoint at mbart-large-cc25_et_rk and are newly initialized: ['model.encoder.global_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/risto/.local/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:690: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lsg_converter.mbart.modeling_lsg_mbart.LSGMBartForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "converter = LSGConverter(max_sequence_length=2048)\n",
    "\n",
    "model_id='mbart-large-cc25_et_rk'\n",
    "model, tokenizer = converter.convert_from_pretrained(model_id, num_global_tokens=7)\n",
    "tokenizer.src_lang = src_lang\n",
    "tokenizer.tgt_lang = tgt_lang\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b298d1ff-992e-4a20-99c4-c3aae20fb8c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('mbart-large-cc25_lsg_2048_et_rk_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2def0ad-aa26-41aa-bdc3-2ffefedb6bab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/opt/work/storage2/localdata/datasience_dev/text/summarization/transformers/mbart-large-cc25_lsg_2048_et_rk/tokenizer_config.json',\n",
       " '/opt/work/storage2/localdata/datasience_dev/text/summarization/transformers/mbart-large-cc25_lsg_2048_et_rk/special_tokens_map.json',\n",
       " '/opt/work/storage2/localdata/datasience_dev/text/summarization/transformers/mbart-large-cc25_lsg_2048_et_rk/sentencepiece.bpe.model',\n",
       " '/opt/work/storage2/localdata/datasience_dev/text/summarization/transformers/mbart-large-cc25_lsg_2048_et_rk/added_tokens.json',\n",
       " '/opt/work/storage2/localdata/datasience_dev/text/summarization/transformers/mbart-large-cc25_lsg_2048_et_rk/tokenizer.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('mbart-large-cc25_lsg_2048_et_rk_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c1b3b-d201-49bf-9362-85cfc93c3366",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## prep data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58462ab6-a200-4870-9404-116e6e9dd483",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_source_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f000e83a-938f-4062-bbd9-81e49581f3bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_target_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3737edea-df3e-4261-9141-ad2c8368fbd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(sample,padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [item for item in sample[\"text\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d4b93f9-c7fd-4683-b21d-15283e217b7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f282165737941a387f0001b92af4d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\", \"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f766165-4f45-40a8-9898-c4a458584f01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec73c69d8aca480494b5c95bf402d074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\", \"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc810e-4647-46f0-8813-a0ac8f5f5a9e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de471419-c631-41db-9055-485596a606d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bcf0960-da63-4f4f-a88b-6bd8cdce783d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c1268-ae7d-4537-9de0-f6b448a5af76",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9394d21f-92d3-42fa-8597-a2ff3c8aad64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStoppingCallback(3, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c4ae189-8f5e-4add-8b34-4cf0c40c2ce6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/risto/.local/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#save to other disc where chmod is supported\n",
    "repository_id = f\"mbart-large-cc25_lsg_2048_et_riigikogu/{dataset_id}_text\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    # push to hub parameters\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=False,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repository_id,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c86c4-b33e-429c-8a8a-e9d975162bcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a MBartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='556' max='8790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 556/8790 07:57 < 1:58:21, 1.16 it/s, Epoch 0.63/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf02f6-e648-45a3-b23e-30a7d27e964a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1dfb433-b776-4c97-b4cf-47c92b1243c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id=\"mbart-large-cc25_lsg_2048_et_riigikogu/riigikogu_text/checkpoint-5274/\"\n",
    "tokenizer = MBartTokenizerFast.from_pretrained('mbart-large-cc25_lsg_2048_et_rk_text',\n",
    "                                               from_slow=True)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8116a954-a542-4638-a974-fa6bf94089ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed77865-cd96-4cd5-ab4d-dda7656add7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_texts_labels_metrics(texts, summaries, model, tokenizer, max_input_length=2048, max_output_length=512, batch_size = 10):\n",
    "    true_labels=tokenizer(\n",
    "        summaries, return_tensors=\"pt\",padding=\"max_length\", truncation=True, max_length=max_input_length\n",
    "    ).input_ids.cpu()\n",
    "    input_ids = tokenizer(\n",
    "        texts, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_input_length\n",
    "    ).input_ids  \n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(0, input_ids.size(0), batch_size):\n",
    "        batch_input_ids = input_ids[i:i + batch_size].to('cuda')\n",
    "        batch_outputs = model.generate(input_ids=batch_input_ids, max_length=max_output_length)\n",
    "        predictions.extend(batch_outputs.cpu().detach().numpy())\n",
    "    max_length = max(len(p) for p in predictions)\n",
    "    padded_predictions = [np.pad(p, (0, max_length - len(p)), mode='constant') for p in predictions]\n",
    "    outputs = torch.tensor(padded_predictions)\n",
    "    eval_preds = (outputs, true_labels.cpu())\n",
    "    metrics = compute_metrics(eval_preds)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b20bc0e8-74c2-443c-8793-b656874ab837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43869/637517378.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  outputs = torch.tensor(padded_predictions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 27.9854,\n",
       " 'rouge2': 9.8125,\n",
       " 'rougeL': 19.8103,\n",
       " 'rougeLsum': 24.7255,\n",
       " 'gen_len': 465.29545454545456}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics=calc_texts_labels_metrics(df_test.text.tolist(), df_test.summary.tolist(), model, tokenizer)\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c751f-8c86-4371-b961-994df10e6767",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c296996-51ae-4d32-93a2-c1e47cb80227",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(text, model, tokenizer, max_input_length=2048, max_new_tokens=512):\n",
    "    input_ids = tokenizer(\n",
    "         text, return_tensors=\"pt\",\n",
    "        max_length=max_input_length\n",
    "    ).input_ids  # Batch size 1\n",
    "    outputs = model.generate(input_ids=input_ids.to('cuda'), max_new_tokens=max_new_tokens)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50105c23-9b7d-491f-a5b7-8ba402fbd9c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sven Sester annab ülevaate riigieelarve seaduse eelnõust ja muudatustest - Sotsiaaldemokraatlik Erakond esitab mitmeid muudatusettepanekuid seoses riigieelarve koostamise ja tasakaalustamisega\n"
     ]
    }
   ],
   "source": [
    "summarize(df_test.text.tolist()[0], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738e5124-c11d-4b9f-8a5c-34fd23bc883f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sven Sester selgitab lühiajalist laenu võtmise tingimusi ja Eesti Panga hinnangut. - Muudatusettepanekud riigi eelarvestrateegia ja kriisiolukordade kohta.\n"
     ]
    }
   ],
   "source": [
    "summarize(df_test.text.tolist()[1], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e317fc-241a-4af6-88c7-5a91ea347967",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Soome kõige populaarsem partei Koonderakond kaotas märtsis tiitli SDP-le, peaministripartei toetus langes ühe protsendi võrra ning Koonderakonna toetus on nüüd 20,6 protsenti. - SDP suurendas toetust naiste ja noorte hulgas, erakondi kannul on Põlissoomlased, rahandusminister Riikka Purra kodupartei toetus ning erakonna toetus on 17,4 protsenti.\n"
     ]
    }
   ],
   "source": [
    "input_text=\"\"\"Veel veebruaris oli Soome kõige populaarsem partei Koonderakond, kuid kaotas märtsis selle tiitli SDP-le. Märtsis langes peaministripartei  toetus ühe protsendi võrra ning Koonderakonna toetus on nüüd 20,6 protsenti.\n",
    "SDP suurendas toetust naiste ja noorte hulgas. Märtsis tõusis SDP toetus 1,9 protsenti ning erakonna toetus on nüüd 21,7 protsenti. \n",
    "Koonderakonna kannul on Põlissoomlased, rahandusminister Riikka Purra kodupartei toetus on 17,4 protsenti.\"\"\"\n",
    "summarize(input_text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50844dcd-1a70-4965-86d8-837473c187b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sven Sester soovitab riigi eelarvestrateegiat arutada Riigikogus - Oluline on tagada eelarve täitmise aruandes esitatud arvandmed ja täpsed nõuded valitsuse esitatavate tegevuskavade ning stabiliseerimisreservi moodustamise ja kasutamise kohta - Komisjon langetas konsensuslikud otsused seoses töötuskindlustusmakse muudatustega riigieelarve seaduse eelnõus\n"
     ]
    }
   ],
   "source": [
    "summarize(df_test.text.tolist()[2], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896f03f8-b54e-4fc4-b3f0-3e64ee158a86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Põhiseaduskomisjoni esimees Jaak Allik juhib põhiseaduskomisjoni täiendavate küsimuste tähelepanu. - Aseesimees Laine Randjärv suunab täiendavate küsimuste esitamise juurde. - Kalev Kotkas ja Rannar Vassiljev esitavad küsimusi seoses valdkonna arengukavaga.\n"
     ]
    }
   ],
   "source": [
    "summarize(df_test.text.tolist()[3], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1279d7-2e2f-450e-aaf1-1245fec0c55e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sven Sester selgitab, et maksukeskkond on stabiilne, kuid muudatused peavad toimuma vastavalt seadustele. - Jaak Allik küsib, milline roll on Riigikogul Rahvusringhäälingu seaduse muutmise menetlemisel.\n"
     ]
    }
   ],
   "source": [
    "summarize(df_test.text.tolist()[4], model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10dd6f-b6a4-4942-af79-3af13f57f4ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Review test data summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33f49b5d-6098-4f31-9cc2-6c1c990357a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(text, model, tokenizer, max_input_length=2048, max_new_tokens=512):\n",
    "    input_ids = tokenizer(\n",
    "         text, return_tensors=\"pt\",\n",
    "        max_length=max_input_length\n",
    "    ).input_ids  # Batch size 1\n",
    "    outputs = model.generate(input_ids=input_ids.to('cuda'), max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6ba021d-3b53-49d6-800a-c40e87fdfddb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_summaries=[]\n",
    "for text in df_test.text.tolist():\n",
    "    summary_=summarize(text, model, tokenizer)\n",
    "    test_summaries.append(summary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaae2211-b565-4956-afe0-0b1e18dc85b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43869/2775572515.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['model_summaries']=test_summaries\n"
     ]
    }
   ],
   "source": [
    "df_test['model_summaries']=test_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "222dd9b7-dc9e-420d-8d5b-19b3ccfd97b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43869/2492651422.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['model_summaries_ntoks']=df_test['model_summaries'].apply(lambda x: tokenizer(x, return_tensors=\"pt\").input_ids.shape[1])\n"
     ]
    }
   ],
   "source": [
    "df_test['model_summaries_ntoks']=df_test['model_summaries'].apply(lambda x: tokenizer(x, return_tensors=\"pt\").input_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d18b423d-dc57-4274-8e9c-5aa455afb73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test['model_summaries_ntoks'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59d004f3-451d-4626-a783-f3f1c167c564",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Rain Epler, Raimond Kaljulaid, Rain Epler, Raimond Raipler, Rain Epler, Rain Epler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler, Raipler'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['model_summaries_ntoks']>400].model_summaries[3542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c60a2b30-b145-4ad2-a477-d70e103cc59a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n Raimond Kaljulaid:  Austatud aseesimees! Siin me nüüd oleme, loetakse ette ajalehti ja ülistatakse elu ENSV‑s. Aga mina olen siin selleks\\xa0… See oli üks eelnev kõne, sõnavõtt, mis rääkis elust ENSV‑s. Mina olen siin, et kaitsta oma head kolleegi Jevgeni Ossinovskit mõningate kolleegide rünnakute eest. Mitte ainult sellepärast, et ta on minu ülemus, minu fraktsiooni juht, vaid sellepärast, et antud juhul on tal õigus. Kõigepealt tahan öelda seda, et oli kunagi Keskerakonnal selline hea põhimõte, et seda Toompea poliitikat ei tooda all-linna. Nüüd võiks olla selline põhimõte, et seda all-linna poliitikat ei tooda Toompeale. Ega mina Sotsiaaldemokraatliku Erakonna Tallinna piirkonna juhina ka ei olnud alguses sellest eelnõust vaimustuses. Aga mul olid pikad kõnelused minister Madis Kallasega ja teiste valitsuse liikmetega. Ja ma saan aru, mis on taust. Piirkondlik majanduslik ebavõrdsus – see on suur probleem. Me peame tunnistama, et on ikka erinev küll, kas me räägime sellest, et vähendatakse näiteks Tallinna tulusid, või me räägime sellest, et mõningal määral väheneb tulevikus tulude kasv. See pole päris üks ja seesama asi. Tallinna eelarve, mille me koos heade kolleegidega Keskerakonnast oleme ühiselt Tallinnas läbi rääkinud, vastu võtnud ja volikogus kinnitanud, on üle miljardi euro. Tallinna puhul me räägime 4,6\\xa0miljoni euro võrra väiksemast eelarve tulude kasvust järgmisel aastal. See on protsentides ausalt öeldes nii väike suhtarv, et ma usun, et nii tugev omavalitsus nagu Tallinn saab sellega hakkama. Ma siiralt loodan, et see Eestile tegelikult vajalik otsus, mis aitab piirkondlikku ebavõrdsust vähendada, väga tõsiselt meie koostööd Tallinnas siiski ei kahjusta. Aga mulle tundub, et te praegu teete Jevgenile asjatult etteheiteid. Jah, võib-olla tõesti Tallinna vaates on ta käitunud väga riigimehelikult ja pidanud silmas Eesti huve, aga samal ajal ma arvan, et sotsiaaldemokraatide ja Keskerakonna koostöö Võrus ja Viljandis võiks ju sellest sammust võita. Need omavalitsused saavad raha juurde. Lõpetuseks. Siin on kolleegid heitnud ette, et mille eest me seisame. Me seisame tegelikult kõigis omavalitsustes ja riigi tasemel valitsuses samade asjade eest. Alampalga tõusu abil näiteks seisame selle eest, et tööinimeste elujärg paraneks, et inimeste ostujõud paraneks. Piirkondliku ebavõrdsuse vähendamise abil seisame sidusama ühiskonna eest. Ühiskonnas võrdsust suurendades seisame selle eest, et iga inimene tunneks, et teda austatakse ja teda väärtustatakse. Ausalt öeldes võiksite te meid minu meelest selles pigem toetada. Aitäh! \\n  \\n Aseesimees Jüri Ratas:  Aitäh! Henn Põlluaas, mis on teie mure? Palun! \\n  \\n Henn Põlluaas:  Aitäh! Mul ei ole muret, mul on soov vasturepliigiks, sellepärast et Raimond Kaljulaid rääkis opositsioonist\\xa0ja\\xa0… \\n  \\n Aseesimees Jüri Ratas:  Aitäh! Aga ma arvan, et ma sain aru küll, kellest Raimond Kaljulaid rääkis. Ta rääkis kahest eelkõnelejast, üks oli Priit Sibul ja teine oli Mart Helme, ma arvan. Kui nemad soovivad vasturepliiki, nad saavad selle. Aga ma ei tea, et ta teist oleks rääkinud. (Hääl saalist.) See laiendus, et opositsioon midagi ründab või mitte, see ei ole selle põhimõte. Aga nende kahe inimese kõnedele, kui nad soovivad vasturepliiki, tõesti otseselt viidati. Nii et läheme edasi. Ma saan aru, et nüüd tuleb kõnetooli Rain Epler ja teeb oma ettekande, mitte fraktsiooni ettekande. Rain Epler, palun teid Riigikogu kõnetooli. \\n  \\n Rain Epler:  Aitäh, hea istungi juhataja! Pean teid kiitma. Kuigi olite vahepeal siin tükk aega ära muud tööd tegemas, siis ikkagi panite tähele, mida ma siin enne tegin ja mida ma nüüd teen. Aitäh! Ma kõigepealt alustuseks tsiteerin lõiku ühest Eesti rahva ennemuistsest jutust pealkirjaga \"Kus Narva endine varandus magab\". See lõik on selline: \"Ülemal räägitud Narva linna rikkuse päevil tulnud ükskord kuri vaenlane kas Vene‑ või Pohlamaalt suure sõjaväega kodanikke riisuma. Õnneks saanud linnarahvas paar päeva enne vaenlaste tulekut salakuulajate läbi sõnumid, nõnda et neil veel aega olnud suurem osa kulda ja hõbedat kokku korjata ja jõesuhu mere ligidale maha matta. Siis pandud linnaväravad kinni ja vahid igale poole kantside peale; toidumoona leitud linnas nii rohkesti, et neil näljakartust ei võinud tulla. Kindlad müürid ja kantsid linna ümber, sügav lai jõgi ühelt poolt ja veega täidetud vallikraavid teiselt poolt ei lasknud vaenlast sisse tulla, kes ligi sügiseni linna piiras ja viimaks asjata kodu poole pidi minema.\" Kui me nüüd mõtleme selle loo peale ja mõtleme selle peale, kuidas vanasti elu käis, siis ta käis niimoodi, et vaenlast oli võimalik märgata piisavalt varakult, et saaks varanduse peitu panna, linnaväravad kinni, saaks toitu varuda ja siis vastu pidada sügiseni, kui vaenlane läinud on. Aga näete, tänapäeval ei ole näiteks Tallinna linna rael ega ka Hiiumaa ja Muhumaa juhtidel võimalik suurt midagi ära teha, sest riigi valitsus on justkui need röövlid, aga selle vahega, et eelnõud rullitakse nii kiiresti läbi, et mingeid ettevalmistusi, kuidas asjaga toime tulla või sellele vastu seista, ei saa teha. Sellest eelnõust veel. Sõltumata sellest, mida meile rääkis oma esimese lugemise ettekandes lugupeetud härra minister, ja sõltumata sellest, mida rääkis ka tänases ettekandes komisjoni ettekandja, siis kuigi seda ei öeldud välja, tegelikult see eelnõu on ju tehtud selleks, et tasandada omavalitsustele sellesama valitsuse teiste eelnõudega, teiste maksueelnõudega tekitatud miinust, peamiselt käibemaksumiinust. Toon siin mõned näited väiksematest omavalitsustest. Lääneranna vald näiteks arvutas välja, et käibemaksu tõus tekitab neile suurusjärgus 32\\xa0000\\xa0–\\xa035\\xa0000 eurot lisakulu ja näe, imede ime, see praegune eelnõu toob neile juurde 34\\xa0000 eurot tulu. Põhimõtteliselt nulliring. Ja kogu see hurraa-jutt siia juurde, et me võtame rikkamatelt vähemaks. Näe, Tallinn ja kujutage ette, isegi rahandusminister Mart Võrklaeva koduvald Rae maksab, seal, ma ei tea, mõnesajad tuhanded. Tallinn maksab rohkem, üle poole sellest 8\\xa0miljonist. See kõik on piinlik. Kui me tahaksime tõesti aidata kohalikke omavalitsusi, siis tänases olustikus on kaks varianti. Kas leitakse sellised meetmed või programmid, mis aitavad erinevaid maakondi majanduslikult järele, mille abil ka elanikkonna maksejõulisus tõuseb, mille abil eelarved saavad endale sellist maksutulu, mille abil arendada oma teenuseid ja teha investeeringuid. Või siis tehakse näiteks väljaspool kuldset ringi otseinvesteeringute programm, mille abil on võimalik kohalike omavalitsuste arengukavades seatud eesmärke ka tegelikult täita. Vaatame, mis on juhtunud Eestis ja Euroopas. Me näeme tänaste uudiste baasil, et Euroopas majandus kasvab, ei ole enam punases. Eesti majandus on eelmise kuu seisuga ikkagi punases ehk –3. Vaatame inflatsiooni: Euroopa keskmine jääb sinna 5% ja 6% vahele, Eesti oma on 11% juures, ületab seda. Me räägime, et laenu ei saa võtta, sest intress on 4% juures. Aga kui inflatsioon on pea 12%, siis see tähendab, et on veel kolm korda odavam võtta laenu, sest raha väärtus iga aastaga väheneb. Ma palun lisaaega kolm minutit. \\n  \\n Aseesimees Jüri Ratas:  Palun, teil on kolm minutit!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.text[3542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c735b8b-1a57-402e-9458-d794b4898d87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Raimond Kaljulaid räägib oma kõnes piirkondliku ebavõrdsuse vähendamisest ja toetab Jevgeni Ossinovskit.\\n- Henn Põlluaas soovib vasturepliiki ja toob esile mure omavalitsuste jaoks seoses eelnõude kiire läbivaatamisega.\\n- Rain Epler kõneleb omavalitsuste eelarvetest ja rõhutab vajadust leida meetmed majandusliku olukorra parandamiseks.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['model_summaries_ntoks']>400].summary[3542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f6407be-0eaa-43e1-9e42-2401391654c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>index_pk</th>\n",
       "      <th>ntoks</th>\n",
       "      <th>ntoks_space</th>\n",
       "      <th>ntoks_mbart</th>\n",
       "      <th>ntoks_gpt35</th>\n",
       "      <th>summary</th>\n",
       "      <th>ntoks_used_gpt35</th>\n",
       "      <th>split</th>\n",
       "      <th>model_summaries</th>\n",
       "      <th>model_summaries_ntoks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>3542</td>\n",
       "      <td>\\n Raimond Kaljulaid:  Austatud aseesimees! S...</td>\n",
       "      <td>PKP-651851</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1045</td>\n",
       "      <td>1830</td>\n",
       "      <td>2856</td>\n",
       "      <td>- Raimond Kaljulaid räägib oma kõnes piirkondl...</td>\n",
       "      <td>3053</td>\n",
       "      <td>test</td>\n",
       "      <td>- Rain Epler, Rain Epler, Rain Epler, Rain Epl...</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "3542        3542   \\n Raimond Kaljulaid:  Austatud aseesimees! S...   \n",
       "\n",
       "        index_pk   ntoks  ntoks_space  ntoks_mbart  ntoks_gpt35  \\\n",
       "3542  PKP-651851  1840.0         1045         1830         2856   \n",
       "\n",
       "                                                summary  ntoks_used_gpt35  \\\n",
       "3542  - Raimond Kaljulaid räägib oma kõnes piirkondl...              3053   \n",
       "\n",
       "     split                                    model_summaries  \\\n",
       "3542  test  - Rain Epler, Rain Epler, Rain Epler, Rain Epl...   \n",
       "\n",
       "      model_summaries_ntoks  \n",
       "3542                    513  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['model_summaries_ntoks']>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b8bc5-96b8-42fc-adc4-4d4468992214",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}